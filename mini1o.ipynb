{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f175977",
   "metadata": {},
   "source": [
    "# config prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee366b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mini1o import DitConfig\n",
    "import torch\n",
    "from diffusers import SanaTransformer2DModel, AutoencoderDC, DPMSolverMultistepScheduler\n",
    "model = SanaTransformer2DModel.from_pretrained(\"Efficient-Large-Model/Sana_600M_512px_diffusers\",subfolder=\"transformer\",torch_dtype=torch.bfloat16)\n",
    "# 加载 VAE 模型，用于将图像编码到 latent 空间\n",
    "vae = AutoencoderDC.from_pretrained(\"Efficient-Large-Model/Sana_600M_512px_diffusers\", subfolder=\"vae\",torch_dtype=torch.bfloat16)\n",
    "# 加载 scheduler，该组件封装了向 latent 添加噪声的操作及时间步信息\n",
    "scheduler = DPMSolverMultistepScheduler.from_pretrained(\"Efficient-Large-Model/Sana_600M_512px_diffusers\",subfolder=\"scheduler\",torch_dtype=torch.bfloat16,)\n",
    "# 从 scheduler 配置中获取训练时的总时间步数（如果配置中没有该项，可设定一个默认值，如 1000）\n",
    "model_config = dict(model.config)\n",
    "vae_config = dict(vae.config)\n",
    "scheduler_config = dict(scheduler.config)\n",
    "dit_config = DitConfig(\n",
    "    model_config=model_config,\n",
    "    vae_config=vae_config,\n",
    "    scheduler_config=scheduler_config\n",
    ")\n",
    "from transformers import AutoConfig\n",
    "path = \"OpenGVLab/InternVL3-1B\"\n",
    "# mllm_config = AutoConfig.from_pretrained(path, trust_remote_code=True)\n",
    "from mini1o import Mini1oMLLM,Mini1oConfig, Mini1o\n",
    "config = Mini1oConfig(dit_config=dit_config.to_dict())\n",
    "config.save_pretrained('ckpt', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ace2f3",
   "metadata": {},
   "source": [
    "# processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4f286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加入特殊token\n",
    "from transformers import AutoTokenizer, AutoProcessor\n",
    "\n",
    "path = \"OpenGVLab/InternVL3-1B\"\n",
    "\n",
    "# 加载 tokenizer 和 processor\n",
    "tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "processor = AutoProcessor.from_pretrained(path)\n",
    "\n",
    "# 定义你要加的 special tokens\n",
    "special_tokens = [\n",
    "    \"<|image_gen_start|>\", \"<|image_gen_pad|>\", \"<|image_gen_end|>\",\n",
    "    # \"<|video_gen_start|>\", \"<|video_gen_pad|>\", \"<|video_gen_end|>\"\n",
    "]\n",
    "\n",
    "# 添加 token，并获得它们的 ID\n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": special_tokens+tokenizer.additional_special_tokens})\n",
    "processor.tokenizer = tokenizer  # 更新 processor 的 tokenizer\n",
    "\n",
    "# 映射到 ID\n",
    "token_ids = {token: tokenizer.convert_tokens_to_ids(token) for token in special_tokens}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ffee1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"OpenGVLab/InternVL3-1B\"\n",
    "from mini1o.processor import Mini1oProcessor, Mini1oImageProcessor\n",
    "from transformers import AutoTokenizer\n",
    "from diffusers.image_processor import PixArtImageProcessor\n",
    "\n",
    "image_processor = Mini1oImageProcessor()\n",
    "gen_image_processor = PixArtImageProcessor()\n",
    "tokenizer = AutoTokenizer.from_pretrained(path, trust_remote_code=True, use_fast=False)\n",
    "chat_template = \"{% set image_count = namespace(value=0) %}{% set video_count = namespace(value=0) %}{% for message in messages %}{% if loop.first and message['role'] != 'system' %}<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n{% endif %}<|im_start|>{{ message['role'] }}\\n{% if message['content'] is string %}{{ message['content'] }}<|im_end|>\\n{% else %}{% for content in message['content'] %}\\n{% if content['type'] == 'image_gen' or 'image_gen' in content %}<|image_gen_start|><|image_gen_pad|><|image_gen_end|>\\n{% elif content['type'] == 'video_gen' or 'video_gen' in content %}<|video_gen_start|><|video_gen_pad|><|video_gen_end|>\\n{% elif content['type'] == 'image' or 'image' in content or 'image_url' in content %}{% set image_count.value = image_count.value + 1 %}{% if add_vision_id %}Picture {{ image_count.value }}: {% endif %}<|vision_start|><|image_pad|><|vision_end|>\\n{% elif content['type'] == 'video' or 'video' in content %}{% set video_count.value = video_count.value + 1 %}{% if add_vision_id %}Video {{ video_count.value }}: {% endif %}<|vision_start|><|video_pad|><|vision_end|>\\n{% elif 'text' in content %}{{ content['text'] }}{% endif %}{% endfor %}<|im_end|>\\n{% endif %}{% endfor %}{% if add_generation_prompt %}<|im_start|>assistant\\n{% endif %}\\n\"\n",
    "\n",
    "processor1o = Mini1oProcessor(image_processor=image_processor, \n",
    "                              tokenizer=tokenizer, \n",
    "                              chat_template=chat_template)\n",
    "# processor1o.save_pretrained('ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"image\": Image.open('1.png').convert('RGB'),\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"Please describe the image shortly.\\n\"\n",
    "            },\n",
    "            # {\n",
    "            #     'image_gen': Image.open('1.png').convert('RGB'),\n",
    "            # }\n",
    "        ],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a0c9a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "<|vision_start|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|vision_end|>\n",
      "Please describe the image shortly.\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = processor1o.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "x = processor1o(\n",
    "    text=[text],\n",
    "    images=[Image.open('1.png').convert('RGB')],\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "print(processor1o.batch_decode(x.input_ids, skip_special_tokens=False)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df39a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yilinjia/.conda/envs/EasyR2/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from mini1o import Mini1oMLLM, Mini1oConfig\n",
    "\n",
    "config = Mini1oConfig.from_pretrained('ckpt')\n",
    "\n",
    "model = Mini1oMLLM.from_config(config, \n",
    "                               torch_dtype=torch.bfloat16，\n",
    "                               use_flash_attn=True,\n",
    "                               trust_remote_code=True,\n",
    "                               device_map='cuda:0').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe97ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "for key, value in x.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        x[key] = value.half()\n",
    "\n",
    "output = model.generate(**x, max_new_tokens=1024, do_sample=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EasyR2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
